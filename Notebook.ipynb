{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DuckDB Meetup\n",
    "\n",
    "## Notebook for Fitbit data analysis with DuckDB\n",
    "Expected to be run in a notebook, DuckDB’s Python client can be used [directly in Jupyter notebook](https://duckdb.org/docs/guides/python/jupyter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Connect to DuckDB\n",
    "%load_ext sql\n",
    "conn = duckdb.connect()\n",
    "%sql conn --alias duckdb\n",
    "\n",
    "# Configurations for jupysql\n",
    "%config SqlMagic.autopandas = True\n",
    "%config SqlMagic.feedback = False\n",
    "%config SqlMagic.displaycon = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Jupyter cell can be used as a SQL cell by using the `%%sql` magic. Query results will be displayed as a Pandas DataFrame. This gives us the ability to alternate between SQL and Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT extension_name, installed, loaded\n",
    "FROM duckdb_extensions()\n",
    "LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying Pandas Dataframes\n",
    "DuckDB is able to find and query any dataframe stored as a variable in the Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.DataFrame.from_dict({\"Trilogy\": [1, 2, 3],\"Movie Name\": [\"A New Hope\", \"The Empire Strikes Back\", \"Return of the Jedi\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe can be specified just like any other table in the FROM clause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT *\n",
    "FROM movies_df;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you can create tables as if you were at the CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "CREATE OR REPLACE TABLE physical_activity\n",
    "as\n",
    "SELECT \n",
    "  startTime + INTERVAL 11 hours as activityTime\n",
    ", activityName\n",
    ", activityLevel\n",
    ", averageHeartRate\n",
    ", calories\n",
    ", duration / 60000 as duration_minutes\n",
    ", steps\n",
    ", distance\n",
    ", distanceUnit\n",
    ", tcxLink\n",
    ", source\n",
    "FROM read_json('./data_fitbit/exercise-*.json'\n",
    ", columns={startTime: 'TIMESTAMP', activityName: 'VARCHAR',  activityLevel: 'JSON', averageHeartRate: 'INTEGER', calories: 'INTEGER', duration: 'INTEGER', steps: 'INTEGER', tcxLink: 'VARCHAR', distance: 'DOUBLE', distanceUnit: 'VARCHAR', source: 'JSON'}\n",
    ", format='array'\n",
    ", timestampformat='%m/%d/%y %H:%M:%S');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can redirect the output of a query into a Python variable, with the `<<` assignment operator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "activity_df <<\n",
    "  SELECT cast(time_bucket(interval '1 month', activityTime\t) as DATE) as activity_day\n",
    "  , activityName\n",
    "  , sum(duration_minutes) as duration\n",
    "  FROM physical_activity\n",
    "  GROUP by 1, 2\n",
    "  ORDER by 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "myplot =sns.barplot(data=activity_df, x=\"activity_day\", y=\"duration\", hue=\"activityName\")\n",
    "myplot.set(xlabel='Month of', ylabel='Duration (min)', title='Monthly Activity Minutes')\n",
    "plt.legend(loc=\"upper right\", title='Activity') \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now define a named query `--save short_trips`, but not execute it `--no-execute`. This tells JupySQL to store the query, but not  execute it yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql --save short_trips --no-execute\n",
    "SELECT *\n",
    "FROM 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-01.parquet'\n",
    "WHERE trip_distance < 6.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `short-trips` query defined previously we can plot a subset of the data. This technique is useful to plot massive datasets directly through the engine  - avoiding both the download of the entire file and avoiding loading all of it into Pandas in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sqlplot histogram --table short_trips --column trip_distance --bins 10 --with short_trips"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
